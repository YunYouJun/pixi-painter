{
  "1": {
    "inputs": {
      "ckpt_name": {
        "content": "aingdiffusion_v113.safetensors",
        "image": null
      },
      "example": "[none]"
    },
    "class_type": "CheckpointLoader|pysssss"
  },
  "2": {
    "inputs": {
      "lora_name": {
        "content": "xiaoyun-ad.safetensors",
        "image": null
      },
      "strength_model": 1,
      "strength_clip": 1,
      "example": "[none]",
      "model": [
        "1",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "LoraLoader|pysssss"
  },
  "6": {
    "inputs": {
      "from_translate": "auto",
      "to_translate": "en",
      "text": "<lora:yuumi:1>, 1girl, solo"
    },
    "class_type": "TranslateTextNode"
  },
  "8": {
    "inputs": {
      "text": [
        "6",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "9": {
    "inputs": {
      "text": [
        "11",
        0
      ],
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "11": {
    "inputs": {
      "from_translate": "auto",
      "to_translate": "en",
      "text": "(worst quality:2),(low quality:2),(normal quality:2),lowres,watermark,\n"
    },
    "class_type": "TranslateTextNode"
  },
  "12": {
    "inputs": {
      "text": [
        "11",
        0
      ],
      "PreviewTextNode_0": "(worst quality:2),(low quality:2),(normal quality:2),lowres,watermark,"
    },
    "class_type": "PreviewTextNode"
  },
  "14": {
    "inputs": {
      "samples": [
        "22",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode"
  },
  "17": {
    "inputs": {
      "image": "Paint_0.png",
      "Clear Canvas": "clear_painer",
      "wPaint_0.png": null
    },
    "class_type": "PainterNode"
  },
  "20": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 512,
      "height": 512,
      "crop": "disabled",
      "image": [
        "17",
        0
      ]
    },
    "class_type": "ImageScale"
  },
  "21": {
    "inputs": {
      "pixels": [
        "20",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncode"
  },
  "22": {
    "inputs": {
      "seed": 389677771544087,
      "steps": 5,
      "cfg": 2,
      "sampler_name": "lcm",
      "scheduler": "ddim_uniform",
      "denoise": 1,
      "model": [
        "2",
        0
      ],
      "positive": [
        "8",
        0
      ],
      "negative": [
        "9",
        0
      ],
      "latent_image": [
        "21",
        0
      ]
    },
    "class_type": "KSampler"
  },
  "39": {
    "inputs": {
      "images": [
        "14",
        0
      ]
    },
    "class_type": "PreviewImage"
  }
}
